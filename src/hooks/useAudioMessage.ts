
import { useState, useCallback } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { useAuth } from '@/contexts/AuthContext';
import { toast } from 'sonner';
import { useWebAudioRecorder } from './useWebAudioRecorder';
import { useAudioPlayer } from './useAudioPlayer';

export interface AudioMessage {
  id: string;
  type: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  audioUrl?: string;
  isPlaying?: boolean;
  duration?: number;
}

export const useAudioMessage = () => {
  const { user } = useAuth();
  const [audioMessages, setAudioMessages] = useState<AudioMessage[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);
  
  const {
    isRecording,
    recordingTime,
    startRecording,
    stopRecording,
    audioLevel
  } = useWebAudioRecorder();
  
  const { isPlaying, playAudio, stopAudio } = useAudioPlayer();

  // Transcrever √°udio usando edge function
  const transcribeAudio = async (audioData: string): Promise<string> => {
    try {
      console.log('üéØ [AUDIO] Iniciando transcri√ß√£o...');
      
      const { data, error } = await supabase.functions.invoke('transcribe-audio', {
        body: { audioData }
      });

      if (error) {
        console.error('‚ùå [AUDIO] Erro na edge function:', error);
        throw new Error(`Erro na transcri√ß√£o: ${error.message}`);
      }

      if (!data?.transcription) {
        throw new Error('Nenhuma transcri√ß√£o retornada');
      }

      console.log('‚úÖ [AUDIO] Transcri√ß√£o recebida:', data.transcription);
      return data.transcription;
      
    } catch (error: any) {
      console.error('‚ùå [AUDIO] Erro na transcri√ß√£o:', error);
      
      // Tratar diferentes tipos de erro
      if (error.message.includes('quota') || error.message.includes('cota')) {
        throw new Error('Cota da OpenAI excedida. Tente novamente mais tarde.');
      } else if (error.message.includes('timeout')) {
        throw new Error('Timeout na transcri√ß√£o. Tente com √°udio mais curto.');
      } else if (error.message.includes('API key')) {
        throw new Error('Problema com a chave da OpenAI.');
      } else {
        throw new Error('Erro na transcri√ß√£o. Verifique sua conex√£o.');
      }
    }
  };

  // Salvar √°udio no Supabase Storage
  const saveAudioToStorage = async (audioBlob: Blob): Promise<string | undefined> => {
    try {
      if (!user) return undefined;
      
      const fileName = `${user.id}/${Date.now()}_audio.webm`;
      
      const { data, error } = await supabase.storage
        .from('chat_audio')
        .upload(fileName, audioBlob, {
          contentType: 'audio/webm'
        });

      if (error) {
        console.error('‚ö†Ô∏è [AUDIO] Erro ao salvar √°udio:', error);
        return undefined;
      }

      const { data: urlData } = supabase.storage
        .from('chat_audio')
        .getPublicUrl(fileName);

      return urlData.publicUrl;
    } catch (error) {
      console.warn('‚ö†Ô∏è [AUDIO] N√£o foi poss√≠vel salvar √°udio:', error);
      return undefined;
    }
  };

  // Processar mensagem de √°udio completa
  const sendAudioMessage = useCallback(async () => {
    if (!isRecording) return;
    
    try {
      setIsProcessing(true);
      console.log('üé§ [AUDIO] Processando mensagem de √°udio...');
      
      // Parar grava√ß√£o e obter dados
      const audioBuffer = await stopRecording();
      if (!audioBuffer) {
        throw new Error('Erro ao obter dados de √°udio');
      }

      // Converter para blob
      const audioBlob = new Blob([audioBuffer], { type: 'audio/webm' });
      
      // Salvar no storage (opcional)
      const audioUrl = await saveAudioToStorage(audioBlob);
      
      // Converter para base64 para transcri√ß√£o
      const base64Audio = btoa(String.fromCharCode(...new Uint8Array(audioBuffer)));
      
      // Transcrever √°udio
      const transcription = await transcribeAudio(base64Audio);
      
      // Adicionar mensagem do usu√°rio
      const userMessage: AudioMessage = {
        id: crypto.randomUUID(),
        type: 'user',
        content: transcription,
        timestamp: new Date(),
        audioUrl,
        duration: recordingTime
      };
      
      setAudioMessages(prev => [...prev, userMessage]);
      
      // Simular resposta da IA
      const aiResponse = `Entendi que voc√™ disse: "${transcription}". Como posso ajudar?`;
      
      const assistantMessage: AudioMessage = {
        id: crypto.randomUUID(),
        type: 'assistant',
        content: aiResponse,
        timestamp: new Date(),
      };
      
      setAudioMessages(prev => [...prev, assistantMessage]);
      
      console.log('‚úÖ [AUDIO] Mensagem processada com sucesso');
      toast.success('Mensagem de √°udio processada!');
      
    } catch (error: any) {
      console.error('‚ùå [AUDIO] Erro ao processar:', error);
      toast.error(`Erro: ${error.message}`);
    } finally {
      setIsProcessing(false);
    }
  }, [isRecording, stopRecording, recordingTime]);

  // Reproduzir √°udio espec√≠fico
  const playMessageAudio = useCallback(async (messageId: string) => {
    const message = audioMessages.find(m => m.id === messageId);
    if (!message?.audioUrl) return;

    setAudioMessages(prev => prev.map(m => ({
      ...m,
      isPlaying: m.id === messageId ? !m.isPlaying : false
    })));

    if (message.isPlaying) {
      stopAudio();
    } else {
      await playAudio(message.audioUrl);
    }
  }, [audioMessages, playAudio, stopAudio]);

  return {
    audioMessages,
    isRecording,
    isProcessing,
    recordingTime,
    audioLevel,
    startRecording,
    sendAudioMessage,
    playMessageAudio,
    setAudioMessages
  };
};
