
import { useState, useCallback } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { useAuth } from '@/contexts/AuthContext';
import { toast } from 'sonner';
import { useWebAudioRecorder } from './useWebAudioRecorder';
import { useAudioPlayer } from './useAudioPlayer';

export interface AudioMessage {
  id: string;
  type: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  audioUrl?: string;
  isPlaying?: boolean;
  duration?: number;
}

export const useAudioMessage = () => {
  const { user } = useAuth();
  const [audioMessages, setAudioMessages] = useState<AudioMessage[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);
  
  const {
    isRecording,
    recordingTime,
    startRecording,
    stopRecording,
    audioLevel
  } = useWebAudioRecorder();
  
  const { isPlaying, playAudio, stopAudio } = useAudioPlayer();

  // Salvar √°udio no Supabase Storage
  const saveAudioToStorage = async (audioBlob: Blob): Promise<string> => {
    if (!user) throw new Error('User not authenticated');
    
    const fileName = `${user.id}/${Date.now()}_audio.webm`;
    
    const { data, error } = await supabase.storage
      .from('chat_audio')
      .upload(fileName, audioBlob, {
        contentType: 'audio/webm'
      });

    if (error) {
      console.error('Erro ao salvar √°udio:', error);
      throw error;
    }

    // Obter URL p√∫blica do √°udio
    const { data: urlData } = supabase.storage
      .from('chat_audio')
      .getPublicUrl(fileName);

    return urlData.publicUrl;
  };

  // Transcrever √°udio usando edge function
  const transcribeAudio = async (audioData: string): Promise<string> => {
    try {
      console.log('üéØ [AUDIO] Iniciando transcri√ß√£o...');
      
      const { data, error } = await supabase.functions.invoke('transcribe-audio', {
        body: { audioData }
      });

      if (error) {
        console.error('‚ùå [AUDIO] Erro na edge function:', error);
        throw new Error(`Erro na transcri√ß√£o: ${error.message}`);
      }

      if (!data?.transcription) {
        throw new Error('Transcri√ß√£o vazia retornada');
      }

      console.log('‚úÖ [AUDIO] Transcri√ß√£o recebida:', data.transcription);
      return data.transcription;
      
    } catch (error: any) {
      console.error('‚ùå [AUDIO] Erro na transcri√ß√£o:', error);
      
      // Tratar diferentes tipos de erro
      if (error.message.includes('quota')) {
        throw new Error('Cota da API excedida. Tente novamente mais tarde.');
      } else if (error.message.includes('rate limit')) {
        throw new Error('Muitas requisi√ß√µes. Aguarde um momento.');
      } else if (error.message.includes('timeout')) {
        throw new Error('Timeout na transcri√ß√£o. Tente com √°udio mais curto.');
      } else {
        throw new Error('Erro na transcri√ß√£o. Verifique sua conex√£o.');
      }
    }
  };

  // Sintetizar voz usando Amazon Polly
  const synthesizeSpeech = async (text: string): Promise<string> => {
    try {
      const { data, error } = await supabase.functions.invoke('polly-synthesize', {
        body: { text }
      });

      if (error) {
        console.error('Erro na s√≠ntese de voz:', error);
        throw error;
      }

      return data.audioData;
    } catch (error) {
      console.error('Erro na s√≠ntese de voz:', error);
      // Falhar silenciosamente na s√≠ntese, mas continuar com texto
      return '';
    }
  };

  // Processar mensagem de √°udio completa
  const sendAudioMessage = useCallback(async () => {
    if (!isRecording) return;
    
    try {
      setIsProcessing(true);
      console.log('üé§ [AUDIO] Processando mensagem de √°udio...');
      
      // Parar grava√ß√£o e obter dados
      const audioBuffer = await stopRecording();
      if (!audioBuffer) {
        throw new Error('Erro ao obter dados de √°udio');
      }

      // Converter para blob e salvar no storage
      const audioBlob = new Blob([audioBuffer], { type: 'audio/webm' });
      
      let audioUrl: string | undefined;
      try {
        audioUrl = await saveAudioToStorage(audioBlob);
      } catch (error) {
        console.warn('‚ö†Ô∏è [AUDIO] N√£o foi poss√≠vel salvar √°udio no storage:', error);
        // Continuar sem salvar no storage
      }
      
      // Converter para base64 para transcri√ß√£o
      const base64Audio = btoa(String.fromCharCode(...new Uint8Array(audioBuffer)));
      
      // Transcrever √°udio
      const transcription = await transcribeAudio(base64Audio);
      
      // Adicionar mensagem do usu√°rio
      const userMessage: AudioMessage = {
        id: crypto.randomUUID(),
        type: 'user',
        content: transcription,
        timestamp: new Date(),
        audioUrl,
        duration: recordingTime
      };
      
      setAudioMessages(prev => [...prev, userMessage]);
      
      // Simular resposta da IA (integrar com sua IA aqui)
      const aiResponse = `Entendi que voc√™ disse: "${transcription}". Como posso ajudar?`;
      
      // Tentar sintetizar resposta (opcional)
      let responseAudioUrl: string | undefined;
      try {
        const responseAudioData = await synthesizeSpeech(aiResponse);
        if (responseAudioData) {
          const responseAudioBytes = atob(responseAudioData);
          const responseAudioArray = new Uint8Array(responseAudioBytes.length);
          for (let i = 0; i < responseAudioBytes.length; i++) {
            responseAudioArray[i] = responseAudioBytes.charCodeAt(i);
          }
          const responseBlob = new Blob([responseAudioArray], { type: 'audio/mp3' });
          responseAudioUrl = URL.createObjectURL(responseBlob);
        }
      } catch (error) {
        console.warn('‚ö†Ô∏è [AUDIO] S√≠ntese de voz falhou, continuando apenas com texto:', error);
      }
      
      // Adicionar mensagem da assistente
      const assistantMessage: AudioMessage = {
        id: crypto.randomUUID(),
        type: 'assistant',
        content: aiResponse,
        timestamp: new Date(),
        audioUrl: responseAudioUrl
      };
      
      setAudioMessages(prev => [...prev, assistantMessage]);
      
      console.log('‚úÖ [AUDIO] Mensagem processada com sucesso');
      toast.success('Mensagem de √°udio processada!');
      
    } catch (error: any) {
      console.error('‚ùå [AUDIO] Erro ao processar:', error);
      toast.error(`Erro: ${error.message}`);
    } finally {
      setIsProcessing(false);
    }
  }, [isRecording, stopRecording, recordingTime]);

  // Reproduzir √°udio espec√≠fico
  const playMessageAudio = useCallback(async (messageId: string) => {
    const message = audioMessages.find(m => m.id === messageId);
    if (!message?.audioUrl) return;

    // Atualizar estado de reprodu√ß√£o
    setAudioMessages(prev => prev.map(m => ({
      ...m,
      isPlaying: m.id === messageId ? !m.isPlaying : false
    })));

    if (message.isPlaying) {
      stopAudio();
    } else {
      await playAudio(message.audioUrl);
    }
  }, [audioMessages, playAudio, stopAudio]);

  return {
    audioMessages,
    isRecording,
    isProcessing,
    recordingTime,
    audioLevel,
    startRecording,
    sendAudioMessage,
    playMessageAudio,
    setAudioMessages
  };
};
