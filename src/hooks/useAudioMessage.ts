import { useState, useCallback } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { useAuth } from '@/contexts/AuthContext';
import { toast } from 'sonner';
import { useWebAudioRecorder } from './useWebAudioRecorder';
import { useAudioPlayer } from './useAudioPlayer';

export interface AudioMessage {
  id: string;
  type: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  audioUrl?: string;
  isPlaying?: boolean;
  duration?: number;
}

export const useAudioMessage = () => {
  const { user } = useAuth();
  const [audioMessages, setAudioMessages] = useState<AudioMessage[]>([]);
  const [isProcessing, setIsProcessing] = useState(false);
  
  const {
    isRecording,
    recordingTime,
    startRecording,
    stopRecording,
    audioLevel
  } = useWebAudioRecorder();
  
  const { isPlaying, playAudio, stopAudio } = useAudioPlayer();

  // Usar Web Speech API em vez da transcri√ß√£o via OpenAI
  const transcribeAudioLocal = async (audioData: string): Promise<string> => {
    try {
      console.log('üéØ [AUDIO] Iniciando transcri√ß√£o local...');
      
      // Para √°udio j√° gravado, retornar uma mensagem padr√£o
      // A transcri√ß√£o em tempo real ser√° feita pelo WebSpeechRecorder
      return 'Transcri√ß√£o de √°udio gravado (use o microfone em tempo real para melhor precis√£o)';
      
    } catch (error: any) {
      console.error('‚ùå [AUDIO] Erro na transcri√ß√£o local:', error);
      throw new Error('Erro na transcri√ß√£o local. Use o reconhecimento em tempo real.');
    }
  };

  // Salvar √°udio no Supabase Storage
  const saveAudioToStorage = async (audioBlob: Blob): Promise<string | undefined> => {
    try {
      if (!user) return undefined;
      
      const fileName = `${user.id}/${Date.now()}_audio.webm`;
      
      const { data, error } = await supabase.storage
        .from('chat_audio')
        .upload(fileName, audioBlob, {
          contentType: 'audio/webm'
        });

      if (error) {
        console.error('‚ö†Ô∏è [AUDIO] Erro ao salvar √°udio:', error);
        return undefined;
      }

      const { data: urlData } = supabase.storage
        .from('chat_audio')
        .getPublicUrl(fileName);

      return urlData.publicUrl;
    } catch (error) {
      console.warn('‚ö†Ô∏è [AUDIO] N√£o foi poss√≠vel salvar √°udio:', error);
      return undefined;
    }
  };

  // Processar mensagem de √°udio com transcri√ß√£o local
  const sendAudioMessage = useCallback(async () => {
    if (!isRecording) return;
    
    try {
      setIsProcessing(true);
      console.log('üé§ [AUDIO] Processando mensagem de √°udio...');
      
      // Parar grava√ß√£o e obter dados
      const audioBuffer = await stopRecording();
      if (!audioBuffer) {
        throw new Error('Erro ao obter dados de √°udio');
      }

      // Converter para blob
      const audioBlob = new Blob([audioBuffer], { type: 'audio/webm' });
      
      // Salvar no storage (opcional)
      const audioUrl = await saveAudioToStorage(audioBlob);
      
      // Converter para base64 para transcri√ß√£o
      const base64Audio = btoa(String.fromCharCode(...new Uint8Array(audioBuffer)));
      
      // Usar transcri√ß√£o local
      const transcription = await transcribeAudioLocal(base64Audio);
      
      // Adicionar mensagem do usu√°rio
      const userMessage: AudioMessage = {
        id: crypto.randomUUID(),
        type: 'user',
        content: transcription,
        timestamp: new Date(),
        audioUrl,
        duration: recordingTime
      };
      
      setAudioMessages(prev => [...prev, userMessage]);
      
      // Simular resposta da IA
      const aiResponse = `Recebi seu √°udio! Para melhor transcri√ß√£o, use o bot√£o de microfone em tempo real.`;
      
      const assistantMessage: AudioMessage = {
        id: crypto.randomUUID(),
        type: 'assistant',
        content: aiResponse,
        timestamp: new Date(),
      };
      
      setAudioMessages(prev => [...prev, assistantMessage]);
      
      console.log('‚úÖ [AUDIO] Mensagem processada com sucesso');
      toast.success('Mensagem de √°udio processada!');
      
    } catch (error: any) {
      console.error('‚ùå [AUDIO] Erro ao processar:', error);
      toast.error(`Erro: ${error.message}`);
    } finally {
      setIsProcessing(false);
    }
  }, [isRecording, stopRecording, recordingTime]);

  // Reproduzir √°udio espec√≠fico
  const playMessageAudio = useCallback(async (messageId: string) => {
    const message = audioMessages.find(m => m.id === messageId);
    if (!message?.audioUrl) return;

    setAudioMessages(prev => prev.map(m => ({
      ...m,
      isPlaying: m.id === messageId ? !m.isPlaying : false
    })));

    if (message.isPlaying) {
      stopAudio();
    } else {
      await playAudio(message.audioUrl);
    }
  }, [audioMessages, playAudio, stopAudio]);

  return {
    audioMessages,
    isRecording,
    isProcessing,
    recordingTime,
    audioLevel,
    startRecording,
    sendAudioMessage,
    playMessageAudio,
    setAudioMessages
  };
};
