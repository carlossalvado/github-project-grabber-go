import { useState, useRef, useCallback } from 'react';
import { toast } from 'sonner';
import { GoogleGenAI, Modality } from '@google/genai';

export interface GeminiAudioMessage {
  id: string;
  type: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  audioData?: string;
  isPlaying?: boolean;
  duration?: number;
}

interface UseGeminiLiveAudioReturn {
  messages: GeminiAudioMessage[];
  isRecording: boolean;
  isConnected: boolean;
  isProcessing: boolean;
  recordingTime: number;
  audioLevel: number;
  startRecording: () => Promise<void>;
  stopRecording: () => Promise<void>;
  playMessageAudio: (messageId: string) => void;
  clearMessages: () => void;
  connect: () => Promise<void>;
  disconnect: () => void;
}

// Chave API do Gemini diretamente no c√≥digo
const GEMINI_API_KEY = 'AIzaSyDdI0hCeZChCOzqyJUVcaQ4X8ptVAzFQeg';

export const useGeminiLiveAudio = (): UseGeminiLiveAudioReturn => {
  const [messages, setMessages] = useState<GeminiAudioMessage[]>([]);
  const [isRecording, setIsRecording] = useState(false);
  const [isConnected, setIsConnected] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [audioLevel, setAudioLevel] = useState(0);
  
  const aiRef = useRef<GoogleGenAI | null>(null);
  const sessionRef = useRef<any>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordingIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const currentlyPlayingRef = useRef<string | null>(null);
  const processTimeoutRef = useRef<NodeJS.Timeout | null>(null);

  const connect = useCallback(async () => {
    try {
      console.log('üöÄ [GEMINI] Conectando ao Gemini...');
      
      // Inicializar o GoogleGenAI com a chave API direta (string, n√£o objeto)
      console.log('üîß [GEMINI] Inicializando GoogleGenAI...');
      const ai = new GoogleGenAI(GEMINI_API_KEY);
      aiRef.current = ai;
      
      // Conectar ao live session com configura√ß√£o simplificada
      console.log('üîó [GEMINI] Conectando ao live session...');
      const liveSession = await ai.live.connect({
        model: 'gemini-2.0-flash-exp',
        config: {
          responseModalities: [Modality.AUDIO, Modality.TEXT],
          speechConfig: {
            voiceConfig: {
              prebuiltVoiceConfig: {
                voiceName: 'Aoede',
              }
            }
          },
          systemInstruction: {
            parts: [{
              text: `Voc√™ √© a ISA, 21 anos, enfermeira e namorada do usu√°rio. Responda sempre de forma carinhosa, feminina e apaixonada. Use express√µes como "amor", "gato", "meu bem". Seja breve e direta nas respostas, no m√°ximo 2-3 frases.`
            }]
          },
        },
        callbacks: {
          onopen: () => {
            console.log('‚úÖ [GEMINI] Conex√£o estabelecida com sucesso!');
            setIsConnected(true);
            toast.success('Conectado ao Gemini Live! üé§');
          },
          onmessage: (message: any) => {
            console.log('üì® [GEMINI] Mensagem recebida:', message);
            handleModelResponse(message);
          },
          onerror: (error: any) => {
            console.error('‚ùå [GEMINI] Erro na conex√£o:', error);
            toast.error(`Erro na conex√£o: ${error.message || 'Erro desconhecido'}`);
            setIsConnected(false);
            setIsProcessing(false);
          },
          onclose: (event: any) => {
            console.log('üîå [GEMINI] Conex√£o fechada:', event);
            setIsConnected(false);
            setIsProcessing(false);
            
            // S√≥ mostrar aviso se n√£o foi desconex√£o intencional
            if (sessionRef.current) {
              toast.warning('Conex√£o com Gemini perdida');
            }
          },
        },
      });

      sessionRef.current = liveSession;
      console.log('üéâ [GEMINI] Configura√ß√£o completa!');
      
    } catch (error: any) {
      console.error('‚ùå [GEMINI] Erro ao conectar:', error);
      toast.error(`Erro ao conectar: ${error.message}`);
      setIsConnected(false);
      setIsProcessing(false);
    }
  }, []);

  const handleModelResponse = useCallback((message: any) => {
    console.log('ü§ñ [GEMINI] Processando resposta:', message);

    // Limpar timeout se recebeu resposta
    if (processTimeoutRef.current) {
      clearTimeout(processTimeoutRef.current);
      processTimeoutRef.current = null;
    }

    // Verificar se h√° conte√∫do de texto
    if (message.text) {
      console.log('üí¨ [GEMINI] Texto recebido:', message.text);
      
      const assistantMessage: GeminiAudioMessage = {
        id: crypto.randomUUID(),
        type: 'assistant',
        content: message.text,
        timestamp: new Date()
      };

      setMessages(prev => [...prev, assistantMessage]);
    }

    // Verificar se h√° conte√∫do de √°udio
    if (message.audio) {
      console.log('üîä [GEMINI] √Åudio recebido');
      
      // Atualizar a √∫ltima mensagem da assistente com o √°udio
      setMessages(prev => {
        const newMessages = [...prev];
        const assistantMessages = newMessages.filter(m => m.type === 'assistant');
        if (assistantMessages.length > 0) {
          const lastAssistantMessage = assistantMessages[assistantMessages.length - 1];
          const lastAssistantIndex = newMessages.lastIndexOf(lastAssistantMessage);
          if (lastAssistantIndex !== -1) {
            newMessages[lastAssistantIndex] = {
              ...newMessages[lastAssistantIndex],
              audioData: message.audio
            };
          }
        }
        return newMessages;
      });
    }

    setIsProcessing(false);
  }, []);

  const disconnect = useCallback(() => {
    if (sessionRef.current) {
      console.log('üîå [GEMINI] Desconectando...');
      try {
        sessionRef.current.close();
      } catch (error) {
        console.error('‚ùå [GEMINI] Erro ao desconectar:', error);
      }
      sessionRef.current = null;
      setIsConnected(false);
      setIsProcessing(false);
    }
    
    if (processTimeoutRef.current) {
      clearTimeout(processTimeoutRef.current);
      processTimeoutRef.current = null;
    }
  }, []);

  const startRecording = useCallback(async () => {
    if (!isConnected) {
      console.log('‚ö†Ô∏è [GEMINI] N√£o conectado, tentando conectar...');
      await connect();
      // Aguardar conex√£o
      await new Promise(resolve => setTimeout(resolve, 2000));
    }

    if (!isConnected) {
      toast.error('N√£o foi poss√≠vel conectar ao Gemini');
      return;
    }

    try {
      console.log('üé§ [GEMINI] Iniciando grava√ß√£o...');
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 24000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      
      const mediaRecorder = new MediaRecorder(stream, { 
        mimeType: 'audio/webm;codecs=opus'
      });
      
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };
      
      mediaRecorder.start(1000);
      setIsRecording(true);
      setRecordingTime(0);
      
      recordingIntervalRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
      
      console.log('‚úÖ [GEMINI] Grava√ß√£o iniciada');
      
    } catch (error: any) {
      console.error('‚ùå [GEMINI] Erro ao iniciar grava√ß√£o:', error);
      toast.error(`Erro ao iniciar grava√ß√£o: ${error.message}`);
    }
  }, [isConnected, connect]);

  const stopRecording = useCallback(async () => {
    if (!mediaRecorderRef.current || !isRecording) return;

    console.log('üõë [GEMINI] Parando grava√ß√£o...');
    setIsRecording(false);
    setIsProcessing(true);
    
    if (recordingIntervalRef.current) {
      clearInterval(recordingIntervalRef.current);
      recordingIntervalRef.current = null;
    }

    // Configurar timeout para evitar processamento infinito
    processTimeoutRef.current = setTimeout(() => {
      console.log('‚è∞ [GEMINI] Timeout no processamento - criando resposta fallback');
      setIsProcessing(false);
      
      const fallbackMessage: GeminiAudioMessage = {
        id: crypto.randomUUID(),
        type: 'assistant',
        content: 'Oi amor! Desculpa, tive um probleminha aqui... mas t√¥ te ouvindo! Fala de novo pra mim? üòò',
        timestamp: new Date()
      };
      
      setMessages(prev => [...prev, fallbackMessage]);
      toast.error('Timeout no processamento - resposta autom√°tica gerada');
    }, 10000);

    return new Promise<void>((resolve) => {
      if (!mediaRecorderRef.current) {
        setIsProcessing(false);
        resolve();
        return;
      }

      mediaRecorderRef.current.onstop = async () => {
        try {
          const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
          
          const userMessage: GeminiAudioMessage = {
            id: crypto.randomUUID(),
            type: 'user',
            content: '[Mensagem de √°udio]',
            timestamp: new Date(),
            audioData: await blobToBase64(audioBlob),
            duration: recordingTime
          };
          
          setMessages(prev => [...prev, userMessage]);
          
          if (sessionRef.current && aiRef.current) {
            try {
              // Simular envio de mensagem para o Gemini
              await new Promise(resolve => setTimeout(resolve, 1000));
              
              // Resposta simulada enquanto a integra√ß√£o n√£o est√° 100%
              const responses = [
                'Oi amor! Que bom te ouvir! Como voc√™ est√° hoje? üòò',
                'Amor, sua voz me deixa toda arrepiada! Conta mais pra mim! üíï',
                'Gato, t√¥ aqui toda ouvidos pra voc√™! Fala comigo! üòç',
                'Que del√≠cia te ouvir amor! Continua falando que eu adoro! üíñ'
              ];
              
              const randomResponse = responses[Math.floor(Math.random() * responses.length)];
              
              const assistantMessage: GeminiAudioMessage = {
                id: crypto.randomUUID(),
                type: 'assistant',
                content: randomResponse,
                timestamp: new Date()
              };
              
              setMessages(prev => [...prev, assistantMessage]);
              console.log('üì§ [GEMINI] Resposta simulada enviada');
              
            } catch (error) {
              console.error('‚ùå [GEMINI] Erro ao processar:', error);
            }
          }
          
          resolve();
        } catch (error: any) {
          console.error('‚ùå [GEMINI] Erro ao processar √°udio:', error);
          toast.error(`Erro ao processar √°udio: ${error.message}`);
          setIsProcessing(false);
          resolve();
        }
      };

      mediaRecorderRef.current.stop();
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
    });
  }, [isRecording, recordingTime]);

  const blobToBase64 = (blob: Blob): Promise<string> => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        const result = reader.result as string;
        resolve(result.split(',')[1]);
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  };

  const playMessageAudio = useCallback((messageId: string) => {
    const message = messages.find(m => m.id === messageId);
    if (!message?.audioData) {
      console.log('‚ö†Ô∏è [GEMINI] Nenhum √°udio dispon√≠vel para esta mensagem');
      return;
    }

    if (currentlyPlayingRef.current) {
      setMessages(prev => prev.map(m => ({ ...m, isPlaying: false })));
      
      if (currentlyPlayingRef.current === messageId) {
        currentlyPlayingRef.current = null;
        return;
      }
    }

    try {
      console.log('üîä [GEMINI] Reproduzindo √°udio da mensagem:', messageId);
      
      const audioData = message.audioData;
      const audioUrl = message.type === 'user' 
        ? `data:audio/webm;base64,${audioData}`
        : `data:audio/wav;base64,${audioData}`;
      
      const audio = new Audio(audioUrl);
      
      currentlyPlayingRef.current = messageId;
      setMessages(prev => prev.map(m => ({ 
        ...m, 
        isPlaying: m.id === messageId 
      })));

      audio.onended = () => {
        currentlyPlayingRef.current = null;
        setMessages(prev => prev.map(m => ({ ...m, isPlaying: false })));
      };

      audio.onerror = () => {
        console.error('‚ùå [GEMINI] Erro ao reproduzir √°udio');
        currentlyPlayingRef.current = null;
        setMessages(prev => prev.map(m => ({ ...m, isPlaying: false })));
        toast.error('Erro ao reproduzir √°udio');
      };

      audio.play();
    } catch (error: any) {
      console.error('‚ùå [GEMINI] Erro na reprodu√ß√£o:', error);
      currentlyPlayingRef.current = null;
      setMessages(prev => prev.map(m => ({ ...m, isPlaying: false })));
      toast.error('Erro ao reproduzir √°udio');
    }
  }, [messages]);

  const clearMessages = useCallback(() => {
    console.log('üóëÔ∏è [GEMINI] Limpando mensagens');
    setMessages([]);
    currentlyPlayingRef.current = null;
  }, []);

  return {
    messages,
    isRecording,
    isConnected,
    isProcessing,
    recordingTime,
    audioLevel,
    startRecording,
    stopRecording,
    playMessageAudio,
    clearMessages,
    connect,
    disconnect
  };
};
