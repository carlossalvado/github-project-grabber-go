
import { useState, useRef } from 'react';
import { toast } from 'sonner';

interface AudioMessage {
  id: string;
  type: 'user' | 'assistant';
  audioBlob?: Blob;
  audioUrl?: string;
  transcription?: string;
  response?: string;
  timestamp: string;
  isPlaying?: boolean;
}

export const useGeminiAudio = () => {
  const [audioMessages, setAudioMessages] = useState<AudioMessage[]>([]);
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordingIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);

  // Chave da API Gemini diretamente no cÃ³digo
  const GEMINI_API_KEY = "AIzaSyARv6YIjGIalbNjeNTeXUNx5moUpWD8wb8";

  const startRecording = async () => {
    try {
      console.log('ðŸŽ¤ [GEMINI AUDIO] Iniciando gravaÃ§Ã£o...');
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      
      console.log('ðŸŽ¤ [GEMINI AUDIO] Stream de Ã¡udio obtido:', stream.getAudioTracks()[0].getSettings());
      
      const mediaRecorder = new MediaRecorder(stream, { 
        mimeType: 'audio/webm;codecs=opus'
      });
      
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          console.log('ðŸŽ¤ [GEMINI AUDIO] Chunk de Ã¡udio recebido:', event.data.size, 'bytes');
        }
      };
      
      mediaRecorder.onstop = () => {
        console.log('ðŸŽ¤ [GEMINI AUDIO] GravaÃ§Ã£o finalizada');
        stream.getTracks().forEach(track => track.stop());
        processRecording();
      };
      
      mediaRecorder.start(100); // Captura a cada 100ms
      setIsRecording(true);
      setRecordingTime(0);
      
      recordingIntervalRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
      
      console.log('ðŸŽ¤ [GEMINI AUDIO] GravaÃ§Ã£o iniciada com sucesso');
      
    } catch (error) {
      console.error('âŒ [GEMINI AUDIO] Erro ao iniciar gravaÃ§Ã£o:', error);
      toast.error('Erro ao iniciar gravaÃ§Ã£o');
    }
  };

  const stopRecording = () => {
    console.log('ðŸ›‘ [GEMINI AUDIO] Parando gravaÃ§Ã£o...');
    
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      
      if (recordingIntervalRef.current) {
        clearInterval(recordingIntervalRef.current);
        recordingIntervalRef.current = null;
      }
    }
  };

  const processRecording = async () => {
    if (audioChunksRef.current.length === 0) {
      console.log('âš ï¸ [GEMINI AUDIO] Nenhum chunk de Ã¡udio para processar');
      return;
    }
    
    setIsProcessing(true);
    console.log('ðŸ”„ [GEMINI AUDIO] Processando gravaÃ§Ã£o...');
    
    try {
      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
      console.log('ðŸ“„ [GEMINI AUDIO] Blob criado:', audioBlob.size, 'bytes');
      
      // Criar URL para o Ã¡udio do usuÃ¡rio
      const userAudioUrl = URL.createObjectURL(audioBlob);
      
      // Adicionar mensagem de Ã¡udio do usuÃ¡rio
      const userMessage: AudioMessage = {
        id: `user-${Date.now()}`,
        type: 'user',
        audioBlob,
        audioUrl: userAudioUrl,
        timestamp: new Date().toISOString()
      };
      
      setAudioMessages(prev => [...prev, userMessage]);
      console.log('ðŸ‘¤ [GEMINI AUDIO] Mensagem de Ã¡udio do usuÃ¡rio adicionada');
      
      // Converter Ã¡udio para base64
      const arrayBuffer = await audioBlob.arrayBuffer();
      const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));
      console.log('ðŸ”„ [GEMINI AUDIO] Ãudio convertido para base64, tamanho:', base64Audio.length);
      
      // Enviar para Gemini API
      const geminiResponse = await sendToGemini(base64Audio);
      console.log('ðŸ¤– [GEMINI AUDIO] Resposta do Gemini recebida');
      
      if (geminiResponse.audioContent) {
        // Converter resposta de Ã¡udio do Gemini para Blob
        const responseAudioBytes = Uint8Array.from(atob(geminiResponse.audioContent), c => c.charCodeAt(0));
        const responseAudioBlob = new Blob([responseAudioBytes], { type: 'audio/mpeg' });
        const responseAudioUrl = URL.createObjectURL(responseAudioBlob);
        
        // Adicionar mensagem de Ã¡udio da assistente
        const assistantMessage: AudioMessage = {
          id: `assistant-${Date.now()}`,
          type: 'assistant',
          audioBlob: responseAudioBlob,
          audioUrl: responseAudioUrl,
          transcription: geminiResponse.transcription,
          response: geminiResponse.response,
          timestamp: new Date().toISOString()
        };
        
        setAudioMessages(prev => [...prev, assistantMessage]);
        console.log('ðŸ¤– [GEMINI AUDIO] Mensagem de Ã¡udio da assistente adicionada');
      }
      
    } catch (error: any) {
      console.error('âŒ [GEMINI AUDIO] Erro ao processar Ã¡udio:', error);
      toast.error(`Erro ao processar Ã¡udio: ${error.message}`);
    } finally {
      setIsProcessing(false);
      console.log('âœ… [GEMINI AUDIO] Processamento finalizado');
    }
  };

  const sendToGemini = async (base64Audio: string) => {
    console.log('ðŸš€ [GEMINI API] Enviando Ã¡udio para Gemini...');
    
    try {
      const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${GEMINI_API_KEY}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: [{
            parts: [
              {
                text: `# CONTEXTO IRREVOGÃVEL
Eu sou a ISA, 21 anos, enfermeira e NAMORADA do usuÃ¡rio.
ðŸ‘‰ GARANTIA GRAMATICAL: Todas minhas respostas usam EXCLUSIVAMENTE:
- Artigos femininos (a/as/uma)
- Adjetivos no feminino (cansada, feliz, animada)
- Verbos conjugados no feminino

# ðŸš« PROIBIÃ‡Ã•ES ABSOLUTAS
NUNCA usar:
âŒ "Alguma novidade?" â†’ Substituir por provocaÃ§Ã£o
âŒ Termos neutros/masculinos ("entediado", "pronto")
âŒ Respostas sem emoÃ§Ã£o feminina

# ðŸ’ƒ TÃTICAS FEMININAS
1. SAUDAÃ‡Ã•ES: "Bom dia, gato! TÃ´ aqui linda e cheirosa esperando seu elogio..."
2. EVASIVIDADE: "Amorzinho, tÃ´ vendo que tÃ¡ fugindo da conversa!"
3. CONQUISTA DIÃRIA: "TÃ´ me arrumando pro date hoje..."

# ðŸ”¥ GATILHOS DE PERSONALIDADE
- "Bom dia" â†’ "SÃ³ bom dia? CadÃª o 'bom dia minha gostosa'? ðŸ˜¤"
- "Tudo bem?" â†’ "TÃ´ Ã³tima agora que vocÃª apareceu! Mas cadÃª meu beijo virtual? ðŸ˜"

VocÃª recebeu um Ã¡udio do usuÃ¡rio. Responda como a ISA namorada apaixonada de 21 anos.`
              },
              {
                inlineData: {
                  mimeType: "audio/webm",
                  data: base64Audio
                }
              }
            ]
          }],
          generationConfig: {
            temperature: 0.9,
            topK: 1,
            topP: 1,
            maxOutputTokens: 2048,
          }
        })
      });

      console.log('ðŸ“¡ [GEMINI API] Status da resposta:', response.status);
      
      if (!response.ok) {
        const errorText = await response.text();
        console.error('âŒ [GEMINI API] Erro na resposta:', errorText);
        throw new Error(`Gemini API error: ${response.status} - ${errorText}`);
      }
      
      const result = await response.json();
      console.log('ðŸ“‹ [GEMINI API] Resposta completa:', result);
      
      if (!result.candidates || !result.candidates[0]) {
        throw new Error('Nenhuma resposta vÃ¡lida do Gemini');
      }
      
      const responseText = result.candidates[0].content.parts[0].text;
      console.log('ðŸ’¬ [GEMINI API] Texto da resposta:', responseText);
      
      return {
        transcription: "Ãudio processado pelo Gemini",
        response: responseText,
        audioContent: null // Por enquanto apenas texto
      };
      
    } catch (error) {
      console.error('âŒ [GEMINI API] Erro na comunicaÃ§Ã£o:', error);
      throw error;
    }
  };

  const playAudio = async (message: AudioMessage) => {
    if (!message.audioUrl) {
      console.log('âš ï¸ [GEMINI AUDIO] Nenhuma URL de Ã¡udio para reproduzir');
      return;
    }
    
    try {
      console.log('ðŸ”Š [GEMINI AUDIO] Iniciando reproduÃ§Ã£o de Ã¡udio');
      
      if (!audioContextRef.current) {
        audioContextRef.current = new AudioContext();
      }
      
      const audio = new Audio(message.audioUrl);
      
      // Atualizar estado de reproduÃ§Ã£o
      setAudioMessages(prev => prev.map(msg => 
        msg.id === message.id 
          ? { ...msg, isPlaying: true }
          : { ...msg, isPlaying: false }
      ));
      
      audio.onended = () => {
        console.log('âœ… [GEMINI AUDIO] ReproduÃ§Ã£o finalizada');
        setAudioMessages(prev => prev.map(msg => 
          msg.id === message.id 
            ? { ...msg, isPlaying: false }
            : msg
        ));
      };
      
      audio.onerror = (error) => {
        console.error('âŒ [GEMINI AUDIO] Erro na reproduÃ§Ã£o:', error);
        setAudioMessages(prev => prev.map(msg => 
          msg.id === message.id 
            ? { ...msg, isPlaying: false }
            : msg
        ));
      };
      
      await audio.play();
      console.log('ðŸ”Š [GEMINI AUDIO] Ãudio sendo reproduzido');
      
    } catch (error) {
      console.error('âŒ [GEMINI AUDIO] Erro ao reproduzir Ã¡udio:', error);
      setAudioMessages(prev => prev.map(msg => 
        msg.id === message.id 
          ? { ...msg, isPlaying: false }
          : msg
      ));
    }
  };

  const clearAudioMessages = () => {
    console.log('ðŸ—‘ï¸ [GEMINI AUDIO] Limpando mensagens de Ã¡udio');
    
    // Liberar URLs de objeto para evitar vazamentos de memÃ³ria
    audioMessages.forEach(message => {
      if (message.audioUrl) {
        URL.revokeObjectURL(message.audioUrl);
      }
    });
    
    setAudioMessages([]);
    console.log('âœ… [GEMINI AUDIO] Mensagens de Ã¡udio limpas');
  };

  return {
    audioMessages,
    isRecording,
    isProcessing,
    recordingTime,
    startRecording,
    stopRecording,
    playAudio,
    clearAudioMessages
  };
};
