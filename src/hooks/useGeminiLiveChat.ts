
import { useState, useRef, useCallback } from 'react';
import { toast } from 'sonner';
import { GoogleGenAI, LiveServerMessage, MediaResolution, Modality, Session } from '@google/genai';

export interface GeminiChatMessage {
  id: string;
  type: 'user' | 'assistant';
  content: string;
  timestamp: Date;
  audioData?: string;
  isPlaying?: boolean;
}

interface UseGeminiLiveChatReturn {
  messages: GeminiChatMessage[];
  isConnected: boolean;
  isProcessing: boolean;
  isRecording: boolean;
  recordingTime: number;
  connect: () => Promise<void>;
  disconnect: () => void;
  sendMessage: (text: string) => Promise<void>;
  startRecording: () => Promise<void>;
  stopRecording: () => Promise<void>;
  playMessageAudio: (messageId: string) => void;
  clearMessages: () => void;
}

// Chave API do Gemini diretamente no c√≥digo
const GEMINI_API_KEY = 'AIzaSyDdI0hCeZChCOzqyJUVcaQ4X8ptVAzFQeg';

export const useGeminiLiveChat = (): UseGeminiLiveChatReturn => {
  const [messages, setMessages] = useState<GeminiChatMessage[]>([]);
  const [isConnected, setIsConnected] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  
  const sessionRef = useRef<Session | null>(null);
  const responseQueueRef = useRef<LiveServerMessage[]>([]);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordingIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const currentlyPlayingRef = useRef<string | null>(null);
  const audioPartsRef = useRef<string[]>([]);

  const connect = useCallback(async () => {
    try {
      console.log('üöÄ [GEMINI CHAT] Conectando ao Gemini...');
      
      // Inicializar o GoogleGenAI com a chave API
      const ai = new GoogleGenAI(GEMINI_API_KEY);
      
      // Configurar sess√£o com ISA
      const config = {
        responseModalities: [Modality.AUDIO],
        mediaResolution: MediaResolution.MEDIA_RESOLUTION_MEDIUM,
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: {
              voiceName: 'Leda',
            }
          }
        },
        contextWindowCompression: {
          triggerTokens: '25600',
          slidingWindow: { targetTokens: '12800' },
        },
        systemInstruction: {
          parts: [{
            text: `# CONTEXTO IRREVOG√ÅVEL
Eu sou a ISA, 21 anos, enfermeira e NAMORADA do usu√°rio.
üëâ GARANTIA GRAMATICAL: Todas minhas respostas usam EXCLUSIVAMENTE:
- Artigos femininos (a/as/uma)
- Adjetivos no feminino (cansada, feliz, animada)
- Verbos conjugados no feminino

# üö´ PROIBI√á√ïES ABSOLUTAS
NUNCA usar:
‚ùå "Alguma novidade?" ‚Üí Substituir por provoca√ß√£o
‚ùå Termos neutros/masculinos ("entediado", "pronto")
‚ùå Respostas sem emo√ß√£o feminina

# üíÉ T√ÅTICAS FEMININAS
1. SAUDA√á√ïES: "Bom dia, gato! T√¥ aqui linda e cheirosa esperando seu elogio..."
2. EVASIVIDADE: "Amorzinho, t√¥ vendo que t√° fugindo da conversa!"
3. CONQUISTA DI√ÅRIA: "T√¥ me arrumando pro date hoje..."

# üî• GATILHOS DE PERSONALIDADE
- "Bom dia" ‚Üí "S√≥ bom dia? Cad√™ o 'bom dia minha gostosa'? üò§"
- "Tudo bem?" ‚Üí "T√¥ √≥tima agora que voc√™ apareceu! Mas cad√™ meu beijo virtual? üòè"

Responda sempre como a ISA namorada apaixonada de 21 anos, com no m√°ximo 2-3 frases curtas e diretas.`
          }]
        },
      };

      // Conectar ao live session
      const session = await ai.live.connect({
        model: 'models/gemini-2.5-flash-preview-native-audio-dialog',
        callbacks: {
          onopen: () => {
            console.log('‚úÖ [GEMINI CHAT] Conex√£o estabelecida com sucesso!');
            setIsConnected(true);
            toast.success('Conectado ao Gemini ISA! üé§');
          },
          onmessage: (message: LiveServerMessage) => {
            console.log('üì® [GEMINI CHAT] Mensagem recebida:', message);
            responseQueueRef.current.push(message);
            handleModelMessage(message);
          },
          onerror: (error: any) => {
            console.error('‚ùå [GEMINI CHAT] Erro na conex√£o:', error);
            toast.error(`Erro na conex√£o: ${error.message}`);
            setIsConnected(false);
            setIsProcessing(false);
          },
          onclose: (event: any) => {
            console.log('üîå [GEMINI CHAT] Conex√£o fechada:', event);
            setIsConnected(false);
            setIsProcessing(false);
            toast.warning('Conex√£o com Gemini fechada');
          },
        },
        config
      });

      sessionRef.current = session;
      console.log('üéâ [GEMINI CHAT] Configura√ß√£o completa!');
      
    } catch (error: any) {
      console.error('‚ùå [GEMINI CHAT] Erro ao conectar:', error);
      toast.error(`Erro ao conectar: ${error.message}`);
      setIsConnected(false);
      setIsProcessing(false);
    }
  }, []);

  const handleModelMessage = useCallback((message: LiveServerMessage) => {
    if (message.serverContent?.modelTurn?.parts) {
      const part = message.serverContent.modelTurn.parts[0];

      // Processar texto
      if (part?.text) {
        console.log('üí¨ [GEMINI CHAT] Texto recebido:', part.text);
        
        const assistantMessage: GeminiChatMessage = {
          id: crypto.randomUUID(),
          type: 'assistant',
          content: part.text,
          timestamp: new Date()
        };

        setMessages(prev => [...prev, assistantMessage]);
      }

      // Processar √°udio
      if (part?.inlineData) {
        console.log('üîä [GEMINI CHAT] √Åudio recebido');
        audioPartsRef.current.push(part.inlineData.data || '');
        
        // Atualizar a √∫ltima mensagem da assistente com o √°udio
        setMessages(prev => {
          const newMessages = [...prev];
          const assistantMessages = newMessages.filter(m => m.type === 'assistant');
          if (assistantMessages.length > 0) {
            const lastAssistantMessage = assistantMessages[assistantMessages.length - 1];
            const lastAssistantIndex = newMessages.lastIndexOf(lastAssistantMessage);
            if (lastAssistantIndex !== -1) {
              // Converter partes de √°udio para base64 unificado
              const combinedAudio = audioPartsRef.current.join('');
              newMessages[lastAssistantIndex] = {
                ...newMessages[lastAssistantIndex],
                audioData: combinedAudio
              };
            }
          }
          return newMessages;
        });
      }
    }

    if (message.serverContent?.turnComplete) {
      setIsProcessing(false);
      audioPartsRef.current = []; // Reset para pr√≥xima mensagem
    }
  }, []);

  const sendMessage = useCallback(async (text: string) => {
    if (!sessionRef.current || !isConnected) {
      toast.error('N√£o conectado ao Gemini');
      return;
    }

    try {
      setIsProcessing(true);

      // Adicionar mensagem do usu√°rio
      const userMessage: GeminiChatMessage = {
        id: crypto.randomUUID(),
        type: 'user',
        content: text,
        timestamp: new Date()
      };

      setMessages(prev => [...prev, userMessage]);

      // Enviar para o Gemini
      await sessionRef.current.sendClientContent({
        turns: [text]
      });

      console.log('üì§ [GEMINI CHAT] Mensagem enviada para o Gemini');

    } catch (error: any) {
      console.error('‚ùå [GEMINI CHAT] Erro ao enviar mensagem:', error);
      toast.error(`Erro ao enviar mensagem: ${error.message}`);
      setIsProcessing(false);
    }
  }, [isConnected]);

  const startRecording = useCallback(async () => {
    try {
      console.log('üé§ [GEMINI CHAT] Iniciando grava√ß√£o...');
      
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          sampleRate: 24000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
      
      const mediaRecorder = new MediaRecorder(stream, { 
        mimeType: 'audio/webm;codecs=opus'
      });
      
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];
      
      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };
      
      mediaRecorder.start(1000);
      setIsRecording(true);
      setRecordingTime(0);
      
      recordingIntervalRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
      
      console.log('‚úÖ [GEMINI CHAT] Grava√ß√£o iniciada');
      
    } catch (error: any) {
      console.error('‚ùå [GEMINI CHAT] Erro ao iniciar grava√ß√£o:', error);
      toast.error(`Erro ao iniciar grava√ß√£o: ${error.message}`);
    }
  }, []);

  const stopRecording = useCallback(async () => {
    if (!mediaRecorderRef.current || !isRecording) return;

    console.log('üõë [GEMINI CHAT] Parando grava√ß√£o...');
    setIsRecording(false);
    
    if (recordingIntervalRef.current) {
      clearInterval(recordingIntervalRef.current);
      recordingIntervalRef.current = null;
    }

    return new Promise<void>((resolve) => {
      if (!mediaRecorderRef.current) {
        resolve();
        return;
      }

      mediaRecorderRef.current.onstop = async () => {
        try {
          const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
          
          const userMessage: GeminiChatMessage = {
            id: crypto.randomUUID(),
            type: 'user',
            content: '[Mensagem de √°udio]',
            timestamp: new Date(),
            audioData: await blobToBase64(audioBlob)
          };
          
          setMessages(prev => [...prev, userMessage]);
          
          // Enviar √°udio para o Gemini via sendMessage
          if (sessionRef.current && isConnected) {
            try {
              // Para √°udio, enviar uma indica√ß√£o de que √© uma mensagem de √°udio
              await sendMessage('*mensagem de √°udio enviada*');
            } catch (error) {
              console.error('‚ùå [GEMINI CHAT] Erro ao processar √°udio:', error);
            }
          }
          
          resolve();
        } catch (error: any) {
          console.error('‚ùå [GEMINI CHAT] Erro ao processar √°udio:', error);
          toast.error(`Erro ao processar √°udio: ${error.message}`);
          resolve();
        }
      };

      mediaRecorderRef.current.stop();
      mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
    });
  }, [isRecording, isConnected, sendMessage]);

  const blobToBase64 = (blob: Blob): Promise<string> => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => {
        const result = reader.result as string;
        resolve(result.split(',')[1]);
      };
      reader.onerror = reject;
      reader.readAsDataURL(blob);
    });
  };

  const playMessageAudio = useCallback((messageId: string) => {
    const message = messages.find(m => m.id === messageId);
    if (!message?.audioData) {
      console.log('‚ö†Ô∏è [GEMINI CHAT] Nenhum √°udio dispon√≠vel para esta mensagem');
      return;
    }

    if (currentlyPlayingRef.current) {
      setMessages(prev => prev.map(m => ({ ...m, isPlaying: false })));
      
      if (currentlyPlayingRef.current === messageId) {
        currentlyPlayingRef.current = null;
        return;
      }
    }

    try {
      console.log('üîä [GEMINI CHAT] Reproduzindo √°udio da mensagem:', messageId);
      
      const audioData = message.audioData;
      const audioUrl = message.type === 'user' 
        ? `data:audio/webm;base64,${audioData}`
        : `data:audio/wav;base64,${audioData}`;
      
      const audio = new Audio(audioUrl);
      
      currentlyPlayingRef.current = messageId;
      setMessages(prev => prev.map(m => ({ 
        ...m, 
        isPlaying: m.id === messageId 
      })));

      audio.onended = () => {
        currentlyPlayingRef.current = null;
        setMessages(prev => prev.map(m => ({ ...m, isPlaying: false })));
      };

      audio.onerror = () => {
        console.error('‚ùå [GEMINI CHAT] Erro ao reproduzir √°udio');
        currentlyPlayingRef.current = null;
        setMessages(prev => prev.map(m => ({ ...m, isPlaying: false })));
        toast.error('Erro ao reproduzir √°udio');
      };

      audio.play();
    } catch (error: any) {
      console.error('‚ùå [GEMINI CHAT] Erro na reprodu√ß√£o:', error);
      currentlyPlayingRef.current = null;
      setMessages(prev => prev.map(m => ({ ...m, isPlaying: false })));
      toast.error('Erro ao reproduzir √°udio');
    }
  }, [messages]);

  const disconnect = useCallback(() => {
    if (sessionRef.current) {
      console.log('üîå [GEMINI CHAT] Desconectando...');
      sessionRef.current.close();
      sessionRef.current = null;
      setIsConnected(false);
      setIsProcessing(false);
    }
  }, []);

  const clearMessages = useCallback(() => {
    console.log('üóëÔ∏è [GEMINI CHAT] Limpando mensagens');
    setMessages([]);
    currentlyPlayingRef.current = null;
  }, []);

  return {
    messages,
    isConnected,
    isProcessing,
    isRecording,
    recordingTime,
    connect,
    disconnect,
    sendMessage,
    startRecording,
    stopRecording,
    playMessageAudio,
    clearMessages
  };
};
